best_lambda, best_alpha, best_beta, best_rho))
# 用最优参数训练最终网络
final_network <- learn_network_improved(
N1 = N1, N2 = N2, expr = expr,
lambda = best_lambda, alpha = best_alpha, beta = best_beta, rho = best_rho,
max_iter = max_iter
)
# 计算最终网络边数
final_edges <- sum(final_network) / 2
cat(sprintf("最终网络实际边数: %d\n", final_edges))
cat("======================================================\n")
return(list(
network = final_network,
params = list(lambda = best_lambda, alpha = best_alpha, beta = best_beta, rho = best_rho),
actual_edges = final_edges
))
}
# 网络性能评估（输出TPR/F1/边数偏差等完整指标）
evaluate_network_performance <- function(net, Y_true, Y_ppi, target_edges = NULL) {
if (sum(net) == 0) {
warning("网络无任何边，性能指标均为0")
return(list(
TPR = 0, FPR = 0, Precision = 0, F1 = 0, PPI_Overlap = 0,
TP = 0, FP = 0, FN = 0,
Actual_Edges = 0, Target_Edges = target_edges, Edge_Deviation = NA
))
}
# 基础参数计算
n_genes <- nrow(Y_true)
total_possible_edges <- n_genes * (n_genes - 1) / 2  # 无向图最大边数
true_edges <- sum(Y_true) / 2                        # 真实网络边数
ppi_edges <- sum(Y_ppi) / 2                          # PPI网络边数
actual_edges <- sum(net) / 2                         # 预测网络边数
# 混淆矩阵指标
tp <- sum(net & Y_true) / 2    # 真阳性边（预测对的真实边）
fp <- sum(net & !Y_true) / 2   # 假阳性边（预测错的非真实边）
fn <- true_edges - tp          # 假阴性边（没预测到的真实边）
# 性能指标
tpr <- if (true_edges > 0) tp / true_edges else 0  # 召回率/TPR
fpr <- if ((total_possible_edges - true_edges) > 0) {
fp / (total_possible_edges - true_edges)  # 假阳性率
} else 0
precision <- if ((tp + fp) > 0) tp / (tp + fp) else 0  # 精确度
f1 <- if ((precision + tpr) > 0) 2 * precision * tpr / (precision + tpr) else 0  # F1分数
ppi_overlap <- if (ppi_edges > 0) sum(net & Y_ppi) / ppi_edges else 0  # 与PPI网络重叠率
# 边数偏差（相对偏差）
edge_deviation <- if (!is.null(target_edges)) {
abs(actual_edges - target_edges) / (target_edges + 1e-6)
} else NA
# 返回完整性能指标
return(list(
TPR = tpr, FPR = fpr, Precision = precision, F1 = f1, PPI_Overlap = ppi_overlap,
TP = tp, FP = fp, FN = fn,
Actual_Edges = actual_edges, Target_Edges = target_edges, Edge_Deviation = edge_deviation
))
}
sum(Y_ppi)/2
sum(X_data)/2
sum(X_data_t)/2
1000*999/2
dim(expr)
cat(sprintf("\n开始贝叶斯优化（初始随机点%d个，引导迭代%d次）...\n", init_points, n_iter))
# ---------------------- 第三步：设置优化参数（用户可调整） ----------------------
# 贝叶斯优化参数
init_points <- 5    # 初始随机抽样点数（建议5-20，越多越稳但越慢）
n_iter <- 30        # 代理模型引导迭代次数（建议20-50）
kappa <- 1.96       # 探索-利用权衡（默认1.96，越大越偏向探索）
parallel_cores <- 10  # 并行核心数（根据服务器配置调整，最大不超过CPU核心数）
# 边数约束参数
target_edges <- 1500  # 目标边数（用户核心需求：希望最终网络有多少条边）
edge_penalty_weight <- 2  # 边数惩罚权重（越大越严格，建议1-5）
# 网络训练参数
admm_max_iter <- 30  # 最终网络ADMM迭代次数（建议20-100）
# 1. 创建优化函数（仅接受待优化参数lambda/alpha/beta/rho，其他参数通过环境传递）
optim_fun <- function(lambda, alpha, beta, rho) {
evaluate_network(
lambda = lambda, alpha = alpha, beta = beta, rho = rho,
N1 = X_data_t, N2 = Y_ppi, expr = expr, Y_true = X_data_true, Y_ppi = Y_ppi,
target_edges = target_edges, edge_penalty_weight = edge_penalty_weight
)
}
# 2. 设置待优化参数的搜索范围（原始值，后续在evaluate_network中转换）
param_bounds <- list(
lambda = c(-3, 3),    # 转换后：~0.05-20
alpha = c(-5, 5),     # 转换后：~0.007-0.993
beta = c(-5, 5),      # 转换后：~0.007-0.993
rho = c(-2, 2)        # 转换后：~0.14-7.39
)
# 3. 调整参数范围避免极端值
adjusted_bounds <- lapply(param_bounds, function(x) c(max(x[1], -10), min(x[2], 10)))
# 4. 并行执行贝叶斯优化
cl <- makeCluster(5)
registerDoParallel(cl)
on.exit(stopCluster(cl))  # 退出时自动关闭并行集群
set.seed(123)  # 固定种子确保可重复
optim_result <- BayesianOptimization(
FUN = optim_fun,
bounds = adjusted_bounds,
init_points = init_points,
n_iter = n_iter,
acq = "ei",  # 期望改进算法（常用）
kappa = kappa,
verbose = TRUE  # 打印每一步优化结果
)
init_points <- 10    # 初始随机抽样点数（建议5-20，越多越稳但越慢）
n_iter <- 30        # 代理模型引导迭代次数（建议20-50）
kappa <- 1.96       # 探索-利用权衡（默认1.96，越大越偏向探索）
parallel_cores <- 10  # 并行核心数（根据服务器配置调整，最大不超过CPU核心数）
# 边数约束参数
target_edges <- 1500  # 目标边数（用户核心需求：希望最终网络有多少条边）
edge_penalty_weight <- 2  # 边数惩罚权重（越大越严格，建议1-5）
# 网络训练参数
admm_max_iter <- 30  # 最终网络ADMM迭代次数（建议20-100）
# ---------------------- 第四步：执行贝叶斯优化（寻找最优参数） ----------------------
cat(sprintf("\n开始贝叶斯优化（初始随机点%d个，引导迭代%d次）...\n", init_points, n_iter))
# 1. 创建优化函数（仅接受待优化参数lambda/alpha/beta/rho，其他参数通过环境传递）
optim_fun <- function(lambda, alpha, beta, rho) {
evaluate_network(
lambda = lambda, alpha = alpha, beta = beta, rho = rho,
N1 = X_data_t, N2 = Y_ppi, expr = expr, Y_true = X_data_true, Y_ppi = Y_ppi,
target_edges = target_edges, edge_penalty_weight = edge_penalty_weight
)
}
# 2. 设置待优化参数的搜索范围（原始值，后续在evaluate_network中转换）
param_bounds <- list(
lambda = c(-3, -1),    # 转换后：~0.05-20
alpha = c(-5, 5),     # 转换后：~0.007-0.993
beta = c(-5, 5),      # 转换后：~0.007-0.993
rho = c(-2, 2)        # 转换后：~0.14-7.39
)
# 3. 调整参数范围避免极端值
adjusted_bounds <- lapply(param_bounds, function(x) c(max(x[1], -10), min(x[2], 10)))
# 4. 并行执行贝叶斯优化
cl <- makeCluster(5)
registerDoParallel(cl)
on.exit(stopCluster(cl))  # 退出时自动关闭并行集群
set.seed(123)  # 固定种子确保可重复
optim_result <- BayesianOptimization(
FUN = optim_fun,
bounds = adjusted_bounds,
init_points = init_points,
n_iter = n_iter,
acq = "ei",  # 期望改进算法（常用）
kappa = kappa,
verbose = TRUE  # 打印每一步优化结果
)
1000*999/2*0.01
source("D:/Academic/A_Molecular_Interaction_Tree/Code/MCMC_Function_新并行_汇总取平均概率_电脑版.R")
packages <- c("lme4","arm","withr","ggplot2","tidyr","ggstats", "GGally", "sna","parallel","foreach","doParallel","iterators","dplyr","igraph","mclust")
#dir <- "/mnt/sda/maoshanjun/liusixuan/packages"
for (pkg in packages) {
library(pkg, character.only = TRUE)
}
# source("/mnt/sda/maoshanjun/liusixuan/Parallel/MCMC_Function_新并行_汇总取平均概率_服务器版.R")
set.seed(1234)
##-------------Parameter-------------------
g <- 1000;domain <- 3 #g是基因个数
m1 <- 10 #聚类
m2 <- 30 #重复随机
#PPI
interact_prob <- 0.8 #真实数据为ppi的概率
X_p_true <- 1      #PPI里百分百真实的概率
#expr
expr_mean <- c(0.7,0);sd <- 0.1 #相关系数
exprmean <- 0;exprsd <- 1;
n_samples=500 #基因表达量个数
#D
p_marginal <- 0.1   #出现边际基因的概率
maxdomain <- 2      #边际基因最多出现在2个区域
D_p_true <- rep(0.5,4) #D数据是真实的比例
#真实连接
ita <- 0.02 #X_data稀疏
sim_prob <- 0.03 #X_sim稀疏[设初始迭代值用的，可不管]
#MCMC
num_iter=100    #迭代次数
iter_size=50    #取最后多少次结果进行汇总看平均结果
X_thresP=(1/2);D_thresP=(1/2)
kappa <- 3; delta <- 2 #Update
selected_p <- c(0.2,0.05)
#pert
change_prob <- c(0.5,0.01) #第1个是有边→无边的概率；第2个是无边→右边概率
##--------------Data----------------
data <- gen_data(g,domain,p_marginal,maxdomain,
D_p_true=D_p_true,X_p_true=X_p_true,ita=ita,
interact_prob,expr_mean,sd,n_samples = n_samples,
exprmean = exprmean, exprsd = exprsd,
ifpert=F,change_prob=change_prob,sim_prob = sim_prob)
D <- data$D
D_true <- data$D_true
X_data <- data$X_data
X_data_true <- data$X_data_true
Y_ppi <- data$Y_ppi
Y_expr <- data$Y_expr
expr <- data$expr
Y_expr_t <- data$Y_expr_t
expr <- t(expr)
Y_expr_0 <- cor(t(expr))
diag(Y_expr_0) <- 0
X_data_sim <- data$X_data_sim
# Y_expr_1 <- sign(Y_expr_0)*((Y_expr_0)^2)
# diag(Y_expr_0) <- 0
# diag(Y_expr_1) <- 0
D_t <- D_true
save(list = ls(),file="g1000_random_数据_聚类_12345_稀疏002.RData")
#----------Pre-set NewData(Cluster)-----------------------------------
A_model <- Mclust(expr)
cluster <- A_model$classification
An <- nrow(expr)
X_data_sm <- matrix(0,An,An)
for (i in 1:(An-1)) {
for (j in (i+1):An) {
if (cluster[i] == cluster[j]) {
# 同一类，为1的概率为0.8
X_data_sm[i, j] <- ifelse(runif(1) < sim_prob, 1, 0)
} else {
# 不同类，为1的概率为0.05
#ALL_X_sim[i, j] <- ifelse(runif(1) < 0.1, 1, 0)
}
# 确保对称性
X_data_sm[j, i] <- X_data_sm[i, j]
}
}
diag(X_data_sm) <- 0
X_data_sm <- as.matrix(X_data_sm )
X_data_sim <- 1L *(X_data_sm | X_data_true)
X_data_t <- X_data_sim
save(list = ls(),file="g1000_random_数据_聚类_12345_稀疏002.RData")
dim(expr)
print("参数设置完")
g5000_m100_iter00 <- Sys.time()
print(paste("准备更新：",Sys.time()))
result <- parallel_network_learning(num_iter=num_iter,iter_size=iter_size,
X_thresP=X_thresP,D_thresP=D_thresP,
domain=domain,kappa=kappa,delta=delta,
X_data_t=X_data_sim,X_data_true=X_data_true,
D_t=D_t,D_true=D_true,Y_ppi=Y_ppi,Y_expr=Y_expr_0,
m=m1,m_2=m2,cores=10,expr=t(expr))
print(paste("结束更新：",Sys.time()))
X_data_t <- result$X_data_t;D_t <- result$D_t
X_data_t0 <- result$X_data_t0;D_t0=result$D_t0
X_data_last <- result$X_data_last;D_last <- result$D_last
diff_D_all <- result$diff_D_all
g5000_m100_iter300 <- Sys.time()
save(list = ls(),file = "g1000_新并行_聚类抽样取汇总概率_模拟_m10m30_12345_稀疏002.RData")
sim1 <- sim_eval(X_data_true=X_data_true,X_data_t,X_data=X_data,D=D,D_t=D_t,D_true =D_true,
ifpert=FALSE)
save(list = ls(),file = "g1000_新并行_聚类抽样取汇总概率_模拟_m10m30_12345_稀疏002.RData")
sum(X_data)/2
sum(X_data_t)/2
sum(X_data_t & X_data)/2
cout_0 <- 1
library(readxl)
library(dplyr)
library(openxlsx)
expr <- read.csv("D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\表达量数据.csv")
expr <- as.data.frame(expr)
count_0 <- apply(expr,1,function(x){return(sum(x==0))})
delete <- which(count_0 > (length(expr)*(2/3))) #筛掉基因表达量2/3为0的
View(expr)
rownames(expr) <- expr[1,]
colnames(expr) <- expr[1,]
View(expr)
expr <- read.csv("D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\表达量数据.csv")
rownames(expr) <- expr[,1]
View(expr)
expr <- read.csv("D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\表达量数据.csv")
expr <- as.data.frame(expr)
rownames(expr) <- expr[,1]
View(expr)
dim(expr[,1])
expr[,1]
expr <- read.csv("D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\表达量数据.csv")
d <- expr[,1]
d1 <- unique(d)
class(d)
c <- duplicated(d)
e <- d[c]
e
which(d==e,drop==F)
which(d==e[1])
expr <- read.csv("D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\表达量数据.csv")
expr <- as.data.frame(expr)
rownames(expr) <- expr[,1]
count_0 <- apply(expr,1,function(x){return(sum(x==0))})
expr <- expr[,-1,drop=F]
View(expr)
count_0 <- apply(expr,1,function(x){return(sum(x==0))})
delete <- which(count_0 > (length(expr)*(2/3))) #筛掉基因表达量2/3为0的
expr_filter <- expr[delete,]
delete <- which(count_0 > (length(expr)*(4/5))) #筛掉基因表达量2/3为0的
expr_filter <- expr[delete,]
write.xlsx(expr_filter, "D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\表达量_筛.csv")
library(scImpute)
scimpute(
count_path = "D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\表达量_筛.csv",
infile = "csv",           # format of input file
outfile = "csv",          # format of output file
out_dir = "D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\零膨胀",           # full path to output directory
labeled = FALSE,          # cell type labels not available
drop_thre = 0.7,          # threshold set on dropout probability
Kcluster = 3,             # 2 cell subpopulations
ncores = 1 ,             # number of cores used in parallel computation
)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(c("AUCell", "RcisTarget", "GENIE3"))
if (!requireNamespace("devtools", quietly = TRUE))
install.packages("devtools")
devtools::install_github("aertslab/SCENIC")
library(WGCNA)
BiocManager::install("GO.db")
expr_b <- read.csv(file = "D:\\Academic\\A_Molecular_Interaction_Tree\\Data\\人体泛组织\\Stomach_top2000_normalized_expression.csv")
rownames(expr_b) <- expr_b[,1]
expr_b <- expr_b[,-1,drop=F]
zero_counts <- apply(expr_b, 1, function(row) sum(row == 0))
save <- which(zero_counts<sort(zero_counts)[1501])
expr_filter <- expr_b[save,]
#expr_filter <- expr_b
# write.csv(d,file = "D:\\Academic\\A_Molecular_Interaction_Tree\\Data\\人体泛组织\\Stomach_top1000_normalized_expression.csv")
###Import Data---------------------
gene_name <- rownames(expr_filter)
ppi_A <- read.csv("D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\All\\蛋白质互作.csv")
ppi_filter <- ppi_A %>%
filter(`InteractorA` %in% gene_name & `InteractorB` %in% gene_name)
library(dpylr)
library(dplyr)
gene_name <- rownames(expr_filter)
ppi_A <- read.csv("D:\\Academic\\A_Molecular_Interaction_Tree\\Empirical_Analysis\\Singal_Cell\\Data\\All\\蛋白质互作.csv")
ppi_filter <- ppi_A %>%
filter(`InteractorA` %in% gene_name & `InteractorB` %in% gene_name)
g <- length(gene_name)
Y_ppi <- matrix(0, nrow = g, ncol = g)
rownames(Y_ppi) <- gene_name
colnames(Y_ppi) <- gene_name
for (i in 1:nrow(ppi_filter)) {
element_1 <- ppi_filter$InteractorA[i]
element_2 <- ppi_filter$InteractorB[i]
idx1 <- which(gene_name == element_1)
idx2 <- which(gene_name == element_2)
Y_ppi[idx1, idx2] <- 1
Y_ppi[idx2, idx1] <- 1
}
diag(Y_ppi) <- 0
#############定位
#########基因表达数据
Y_expr <- cor(t(expr_filter), method = "spearman")
diag(Y_expr) <- 0
threshold <- 0.2  # 可根据需求调整（如0.15、0.25）
network_matrix <- ifelse(abs(Y_expr) > threshold, 1, 0)
diag(network_matrix )/2
threshold <- 0.2  # 可根据需求调整（如0.15、0.25）
network_matrix <- ifelse(abs(Y_expr) > threshold, 1, 0)
sum(network_matrix )/2
X_sim <- network_matrix
sum(X_sim)/2
sum(X_sim & Y_ppi)/2
sum(X_sim & Y_ppi)/sum(Y_ppi)
(sum(X_sim & Y_ppi)+sum(!X_sim & !Y_ppi))/(ncol(X_sim)*(ncol(X_sim)-1))
setwd("D:\\Academic\\Treegraph")
library(devtools)
devtools::document()
file.rename("DESCRIPTION.txt", "DESCRIPTION")
devtools::document()
devtools::document()
library(TreeGraph)
?tree_graph_analysis
# 删除所有生成的文档文件
unlink("man", recursive = TRUE)
dir.create("man")
# 重新生成文档
devtools::document()
library(TreeGraph)
?tree_graph_analysis
unlink("man", recursive = TRUE)
unlink("NAMESPACE")
# 2. 删除DESCRIPTION中的RoxygenNote行（如果有）
desc <- readLines("DESCRIPTION")
desc <- desc[!grepl("^RoxygenNote:", desc)]
writeLines(desc, "DESCRIPTION")
# 3. 重新生成文档
devtools::document()
if(file.exists("man/tree_graph_analysis.Rd")) {
rd_content <- readLines("man/tree_graph_analysis.Rd")
cat("=== Rd文件内容 ===\n")
cat(rd_content, sep = "\n")
# 特别查看问题区域
cat("\n=== 问题区域 (45-80行) ===\n")
if(length(rd_content) >= 80) {
cat(rd_content[45:80], sep = "\n")
}
}
# 检查当前会话的编码
Sys.getlocale()
# 尝试设置UTF-8编码
Sys.setlocale(category = "LC_ALL", locale = "en_US.UTF-8")
# 重新生成文档
devtools::document()
library(TreeGraph)
.show_help()
?tree_graph_analysis
library(TreeGraph)
# 测试数据生成
test_data <- generate_tree_data(n_samples = 50)
print("测试数据生成:")
print(head(test_data))
print(dim(test_data))
# 测试基本分析功能
print("测试基本分析:")
result1 <- tree_graph_analysis(data = test_data,
coverage = 0.95,
angle_method = "mean")
print(result1)
# 测试不同角度方法
print("测试中位数方法:")
result2 <- tree_graph_analysis(data = test_data,
coverage = 0.9,
angle_method = "median")
print(result2)
# 完全清理并重新生成
unlink("man", recursive = TRUE)
dir.create("man")
unlink("NAMESPACE")
# 重新生成文档
devtools::document()
# 重新安装
devtools::install()
# 测试帮助
library(TreeGraph)
?tree_graph_analysis
?tree_graph_analysis
# 设置工作目录到包根目录
setwd("D:/Academic/Treegraph")
# 创建README.md文件 - 修正版本
writeLines('# TreeGraph R Package
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
An R package for analyzing angle statistics in tree-structured graphs with customizable coverage levels and angle calculation methods.
## 📦 Installation
You can install the development version from GitHub:
```r
# Install from GitHub
devtools::install_github("YOUR_USERNAME/TreeGraph")
# Load the package
library(TreeGraph)
# 设置工作目录到包根目录（根据实际路径调整）
setwd("D:/Academic/Treegraph")
# 创建README.md文件 - 修正版本
writeLines('# TreeGraph R Package
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
An R package for analyzing angle statistics in tree-structured graphs with customizable coverage levels and angle calculation methods.
## 📦 Installation
You can install the development version from GitHub:
```r
# 安装前确保已安装devtools
if (!require("devtools")) install.packages("devtools")
# 替换YOUR_GITHUB_USERNAME为你的GitHub用户名（例如"username/Treegraph"）
devtools::install_github("YOUR_GITHUB_USERNAME/Treegraph")
# 加载包（注意包名大小写与实际包名一致，此处与目录名Treegraph保持一致）
library(Treegraph)
# 设置工作目录到包根目录（根据实际路径调整）
setwd("D:/Academic/Treegraph")
# 创建README.md文件 - 修正版本
setwd("D:/Academic/Treegraph")
setwd("D:/Academic/Treegraph")
# 创建README.md内容
readme_content <- "# TreeGraph R Package
R package for analyzing angle statistics in tree-structured graphs with customizable coverage levels and angle calculation methods.
""
# 创建README.md内容
readme_content <- "# TreeGraph R Package
R package for analyzing angle statistics in tree-structured graphs with customizable coverage levels and angle calculation methods."
setwd("D:/Academic/Treegraph")
readme_content <- "# TreeGraph R Package
R package for analyzing angle statistics in tree-structured graphs with customizable coverage levels and angle calculation methods.
## Installation
```r
# Install from GitHub
devtools::install_github(\"YOUR_USERNAME/TreeGraph\")
# Load the package
library(TreeGraph)"
writeLines(readme_content, "README.md")
setwd("D:/Academic/Treegraph")
readme_content <- "# TreeGraph R Package
R package for analyzing angle statistics in tree-structured graphs with customizable coverage levels and angle calculation methods.
## Installation
```r
# Install from GitHub
devtools::install_github(\"LSX-69/Treegraph\")
# Load the package
library(TreeGraph)"
writeLines(readme_content, "README.md")
setwd("D:/Academic/Treegraph")
readme_content <- "# Treegraph R Package
R package for analyzing angle statistics in tree-structured graphs with customizable coverage levels and angle calculation methods.
## Installation
```r
# Install from GitHub
devtools::install_github(\"LSX-69/Treegraph\")
# Load the package
library(Treegraph)"
writeLines(readme_content, "README.md")
system('git config --global user.name "LiuSX-69"')
system('git config --global user.email "909925188@qq.com"')
setwd("D:/Academic/Treegraph")
readme_content <- "# Treegraph R Package
R package for analyzing angle statistics in tree-structured graphs with customizable coverage levels and angle calculation methods.
## Installation
```r
# Install from GitHub
devtools::install_github(\"LiuSX-69/Treegraph\")
# Load the package
library(Treegraph)"
writeLines(readme_content, "README.md")
